{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%\n",
    "% Project Name: USSP\n",
    "% Description: main function of experiment 6.3, the CNN in NICO \n",
    "% Author: Yang Jinjing\n",
    "% Email: yangjinjing94@163.com\n",
    "% Date: 2025-04-19\n",
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the uniform design\n",
    "import numpy as np \n",
    "import pyunidoe as pydoe\n",
    "uni_design=pydoe.gen_ud(n=2000, s=20, q=2000, init=\"rand\", crit=\"CD2\", maxiter=50, vis=False)\n",
    "print(np.shape(uni_design[\"final_design\"]))\n",
    "np.save('UD_2000_20.npy', uni_design[\"final_design\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the LHD design\n",
    "from pyDOE import *\n",
    "lhd_design=lhs(20, samples=2000, criterion='maximin')\n",
    "print(np.shape(lhd_design))\n",
    "print(lhd_design)\n",
    "np.save('LHD_2000_20.npy', lhd_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the package\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import pickle\n",
    "import NICO_transforms\n",
    "reload(NICO_transforms)\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "import USSP\n",
    "reload(USSP)\n",
    "import IBOSS\n",
    "import LowCon\n",
    "reload(LowCon)\n",
    "\n",
    "import NICO_ResNet50_TrainTest\n",
    "reload(NICO_ResNet50_TrainTest)\n",
    "\n",
    "class DatasetFromList(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enhance the Autumn dataset\n",
    "# load the original dataset\n",
    "train_dir = \"../realdata/NICO/public_dg_0416/train/autumn\"\n",
    "original_dataset = datasets.ImageFolder(root=train_dir)\n",
    "\n",
    "\n",
    "# enhance the dataset\n",
    "augmented_data = []\n",
    "for image, label in original_dataset:\n",
    "    transformed_images = NICO_transforms.NICO_transforms(image)\n",
    "    for transformed_image in transformed_images:\n",
    "        augmented_data.append((transformed_image, label))\n",
    "\n",
    "full_train_set = DatasetFromList(augmented_data)\n",
    "print(f\"Length of the enhanced file: {len(full_train_set)}\") \n",
    "\n",
    "\n",
    "\n",
    "filename = \"NICO_autumn_enhanced_dataset.pkl\"\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(full_train_set, f)\n",
    "\n",
    "print(f\"Saved to file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the enhanced autumn file\n",
    "with open(\"NICO_autumn_enhanced_dataset.pkl\", \"rb\") as f:\n",
    "    full_train_set = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enhance the test dataset and save to pkl\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        torch.manual_seed(11)\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "def preprocess_test_data(test_dirs, output_dir=\"preprocessed_test_data\"):\n",
    "    \"\"\"\n",
    "    Preprocesses test datasets by applying transformations and saving them as pickle files.\n",
    "\n",
    "    Args:\n",
    "        test_dirs (list): A list of paths to the directories containing the test scenarios.\n",
    "        output_dir (str): The directory to save the preprocessed .pkl files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    seed = 11\n",
    "    for scenario_path in test_dirs:\n",
    "        scenario_name = os.path.basename(scenario_path.rstrip('/'))\n",
    "        print(f\"Preprocessing scenario: {scenario_name}\")\n",
    "\n",
    "        # --- Preprocess Original Data ---\n",
    "        original_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        original_test_set = datasets.ImageFolder(root=scenario_path, transform=original_transform)\n",
    "        original_data = [item for item in original_test_set] # Store (image, label) tuples\n",
    "        output_path_original = os.path.join(output_dir, f\"{scenario_name}_original.pkl\")\n",
    "        with open(output_path_original, 'wb') as f:\n",
    "            pickle.dump(original_data, f)\n",
    "        print(f\"Saved preprocessed original data to: {output_path_original}\")\n",
    "\n",
    "        # --- Preprocess Noisy Data ---\n",
    "        min_std = 0.1\n",
    "        max_std = 0.2\n",
    "        random.seed(seed)\n",
    "        random_std = random.uniform(min_std, max_std)\n",
    "        gaussian_noise_transform = AddGaussianNoise(0., random_std)\n",
    "        noisy_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            gaussian_noise_transform,\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        noisy_test_set = datasets.ImageFolder(root=scenario_path, transform=noisy_transform)\n",
    "        noisy_data = [item for item in noisy_test_set] # Store (image, label) tuples\n",
    "        output_path_noisy = os.path.join(output_dir, f\"{scenario_name}_noisy.pkl\") # Modified noisy output name\n",
    "        with open(output_path_noisy, 'wb') as f:\n",
    "            pickle.dump(noisy_data, f)\n",
    "        print(f\"Saved preprocessed noisy data to: {output_path_noisy}\")\n",
    "\n",
    "        seed += 1\n",
    "\n",
    "test_dirs = [           # test seniors\n",
    "    \"../realdata/NICO/public_dg_0416/train/dim\",\n",
    "    \"../realdata/NICO/public_dg_0416/train/grass\",\n",
    "    \"../realdata/NICO/public_dg_0416/train/outdoor\",\n",
    "    \"../realdata/NICO/public_dg_0416/train/rock\",\n",
    "    \"../realdata/NICO/public_dg_0416/train/water\"\n",
    "]\n",
    "\n",
    "    # Preprocess the data (run this once)\n",
    "preprocess_test_data(test_dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction Simple CNN\n",
    "# UniformLoss: Encourages features to be uniformly distributed on the unit hypersphere\n",
    "class UniformLoss(nn.Module):\n",
    "    def __init__(self, t=2.0, lambda_u=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            t: Temperature parameter, adjusts the influence of distance\n",
    "            lambda_u: Loss scaling factor\n",
    "        \"\"\"\n",
    "        super(UniformLoss, self).__init__()\n",
    "        self.t = t\n",
    "        self.lambda_u = lambda_u\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: [batch_size, feat_dim], feature vectors extracted by the network\n",
    "        Returns:\n",
    "            uniform_loss: Uniformity loss\n",
    "        \"\"\"\n",
    "        # First, perform L2 normalization on the features to ensure they are on the unit hypersphere\n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "        # Calculate the cosine similarity matrix between features (direct inner product after normalization)\n",
    "        sim_matrix = torch.mm(features, features.t())\n",
    "        # Using the normalization property, the Euclidean distance can be written as: ||x-y||^2 = 2 - 2*(xÂ·y)\n",
    "        distances = 2 - 2 * sim_matrix\n",
    "\n",
    "        n = features.size(0)\n",
    "        # Exclude the diagonal (distance from itself is 0)\n",
    "        mask = torch.eye(n, dtype=torch.bool, device=features.device)\n",
    "        distances = distances[~mask].view(n, n - 1)\n",
    "\n",
    "        # Calculate the uniformity loss: log(mean(exp(-t * distance)))\n",
    "        loss = torch.log(torch.mean(torch.exp(-self.t * distances)))\n",
    "        return self.lambda_u * loss\n",
    "\n",
    "# Define a custom CNN model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=60, feature_dim=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Feature extraction part\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # Input: 3 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # Fully connected layer after feature extraction\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(64 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, feature_dim)\n",
    "        )\n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        features = self.feature_extractor(x)  # Extract feature_dim dimensional features\n",
    "        output = self.classifier(features)    # Get the classification output\n",
    "        return output, features\n",
    "\n",
    "# Initialize the model, loss functions, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomCNN(num_classes=60, feature_dim=10).to(device)\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss().to(device)                      # Main classification loss\n",
    "criterion_uniform = UniformLoss(t=2.0, lambda_u=0.003).to(device)  # Uniformity loss\n",
    "\n",
    "# Optimizer updates both model parameters and learnable parameters in UniformLoss (if any)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': criterion_uniform.parameters(), 'weight_decay': 5e-4}\n",
    "], lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train_model(dataloader, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs, features = model(images)\n",
    "\n",
    "            # Calculate cross-entropy and uniformity loss\n",
    "            loss_ce = criterion_ce(outputs, labels)\n",
    "            loss_uniform = criterion_uniform(features)\n",
    "            total_loss = loss_ce + loss_uniform\n",
    "\n",
    "            # Backward propagation\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(progress_bar))\n",
    "        print(f\"Epoch {epoch+1}, Total Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "# Assuming full_train_set is already defined\n",
    "dataloader = DataLoader(full_train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "# Start training\n",
    "train_model(dataloader, epochs=30)\n",
    "\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features_all =[]\n",
    "    labels_all =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            _, features = model(images)\n",
    "            features_all.append(features)\n",
    "            labels_all.append(labels)\n",
    "\n",
    "    features_all = torch.cat(features_all, dim=0)\n",
    "    labels_all = torch.cat(labels_all, dim=0)\n",
    "    np.save('supervised_features.npy', features_all.cpu().numpy())\n",
    "    return features_all, labels_all\n",
    "# Extract features\n",
    "features, labels = extract_features(model, dataloader)\n",
    "print(np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using a pre-trained ResNet50 feature extraction CNN -\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=10):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Load the pre-trained ResNet50 model (IMAGENET1K_V2)\n",
    "        self.resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "        # Freeze all convolutional layer parameters except for layer4\n",
    "        for name, param in self.resnet50.named_parameters():\n",
    "            if not name.startswith('layer4'):\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Replace the last fully connected layer of ResNet50 to extract features of the specified dimension\n",
    "        num_ftrs = self.resnet50.fc.in_features\n",
    "        self.feature_extractor = nn.Linear(num_ftrs, feature_dim)\n",
    "        self.classifier = nn.Linear(feature_dim, 60) # Assuming the number of classes is 60\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the convolutional layers of ResNet50\n",
    "        x = self.resnet50.conv1(x)\n",
    "        x = self.resnet50.bn1(x)\n",
    "        x = self.resnet50.relu(x)\n",
    "        x = self.resnet50.maxpool(x)\n",
    "\n",
    "        x = self.resnet50.layer1(x)\n",
    "        x = self.resnet50.layer2(x)\n",
    "        x = self.resnet50.layer3(x)\n",
    "        x = self.resnet50.layer4(x)\n",
    "\n",
    "        x = self.resnet50.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Pass through the custom feature extraction layer\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.classifier(features) # Add a classifier if needed\n",
    "        return output, features\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeatureExtractor(feature_dim=10).to(device)\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss().to(device)  # Main classification loss\n",
    "\n",
    "# Optimize only the parameters of layer4 and the custom feature extraction layer and classifier\n",
    "params_to_optimize = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        params_to_optimize.append(param)\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_optimize, lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train_model(dataloader, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs, features = model(images)\n",
    "\n",
    "            # Calculate cross-entropy loss\n",
    "            loss_ce = criterion_ce(outputs, labels)\n",
    "            total_loss = loss_ce\n",
    "\n",
    "            # Backward propagation\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(progress_bar))\n",
    "        print(f\"Epoch {epoch+1}, Total Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "# Start training\n",
    "dataloader = DataLoader(full_train_set, batch_size=64, shuffle=True)\n",
    "train_model(dataloader, epochs=30)\n",
    "\n",
    "# Feature extraction part remains unchanged\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features_all =[]\n",
    "    labels_all =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            _, features = model(images)\n",
    "            features_all.append(features.cpu().numpy())\n",
    "            labels_all.append(labels.cpu().numpy())\n",
    "\n",
    "    features_all = np.concatenate(features_all, axis=0)\n",
    "    labels_all = np.concatenate(labels_all, axis=0)\n",
    "    np.save('supervised_features.npy', features_all)\n",
    "    return features_all, labels_all\n",
    "\n",
    "# Extract features\n",
    "features, labels = extract_features(model, dataloader)\n",
    "print(np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsampling USSP IBOSS LowCon SRS and Baseline\n",
    "import numpy as np\n",
    "UD=np.load('UD_2000_10.npy')    \n",
    "LHD=np.load('LHD_2000_10.npy')\n",
    "NICO_autumn_feature=np.load('supervised_features.npy')    \n",
    "print(np.shape(UD))\n",
    "n_samples = NICO_autumn_feature.shape[0]\n",
    "\n",
    "N=2000\n",
    "_,NICO_autumn_subsample_USSP_index=USSP.USSP(NICO_autumn_feature,UD)\n",
    "NICO_autumn_subsample_IBOSS_index,_=IBOSS.IBOSS(NICO_autumn_feature, N)\n",
    "NICO_autumn_subsample_Lowcon_index=LowCon.LowCon_without_rep(NICO_autumn_feature, LHD)\n",
    "NICO_autumn_subsample_srs_index=np.random.choice(n_samples, size=N, replace=False)\n",
    "NICO_autumn_subsample_all_index=arr = np.arange(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline training\n",
    "# filename = \"NICO_autumn_enhanced_dataset.pkl\"\n",
    "# with open(filename, 'rb') as f:\n",
    "#     full_train_set = pickle.load(f)\n",
    "\n",
    "all_results = {}\n",
    "samples_all={\"all\": NICO_autumn_subsample_all_index}    # Index all\n",
    "for subset_name, indices in samples_all.items():\n",
    "    # Train\n",
    "    model_path = f\"best_model_{subset_name}.pth\"  \n",
    "    best_val_acc, log = NICO_ResNet50_TrainTest.train_model(full_train_set,indices, model_path,64,10)\n",
    "    \n",
    "    # Test \n",
    "    test_accs = NICO_ResNet50_TrainTest.test_scenarios(model_path)\n",
    "    \n",
    "    # Result\n",
    "    all_results[subset_name] = {\n",
    "        'val_acc': best_val_acc,\n",
    "        'test_accs': test_accs,\n",
    "        'log': log\n",
    "    }\n",
    "\n",
    "\n",
    "for subset_name, metrics in all_results.items():\n",
    "    avg_test = np.mean(list(metrics['test_accs'].values()))\n",
    "    print(f\"{subset_name}: ValAcc={metrics['val_acc']:.1f}% | AvgTestAcc={avg_test:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USSP IBOSS LowCon SRS training\n",
    "all_results = {}\n",
    "subsamples = {\n",
    "        # \"USSP\": NICO_autumn_subsample_USSP_index,\n",
    "        \"IBOSS\": NICO_autumn_subsample_IBOSS_index,\n",
    "        \"Lowcon\": NICO_autumn_subsample_Lowcon_index,\n",
    "        \"srs\": NICO_autumn_subsample_srs_index,  # random index\n",
    "}   \n",
    "for subset_name, indices in subsamples.items():\n",
    "    # train \n",
    "    model_path = f\"best_model_{subset_name}.pth\"  \n",
    "    best_val_acc, log = NICO_ResNet50_TrainTest.train_model(full_train_set,indices, model_path,32,10,0.0001)\n",
    "    \n",
    "    # test\n",
    "    test_accs = NICO_ResNet50_TrainTest.test_scenarios(model_path)\n",
    "    \n",
    "    # result\n",
    "    all_results[subset_name] = {\n",
    "        'val_acc': best_val_acc,\n",
    "        'test_accs': test_accs,\n",
    "        'log': log\n",
    "    }\n",
    "\n",
    "# result analysis\n",
    "print(\"\\nAccuracy results:\")\n",
    "for subset_name, metrics in all_results.items():\n",
    "    avg_test = np.mean(list(metrics['test_accs'].values()))\n",
    "    print(f\"{subset_name}: ValAcc={metrics['val_acc']:.1f}% | AvgTestAcc={avg_test:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USSP tune\n",
    "import NICO_ResNet50_TrainTest\n",
    "reload(NICO_ResNet50_TrainTest)\n",
    "import USSP\n",
    "reload(USSP)\n",
    "import numpy as np\n",
    "\n",
    "all_results = {}\n",
    "num_repetitions = 20\n",
    "\n",
    "subsamples_to_run = {\n",
    "    \"USSP\": None, # We will generate the indices inside the loop\n",
    "}\n",
    "\n",
    "for subset_name in subsamples_to_run:\n",
    "    all_val_accs = []\n",
    "    all_test_accs_list = []\n",
    "    all_logs = []\n",
    "\n",
    "    print(f\"\\nRunning {subset_name} for {num_repetitions} repetitions...\")\n",
    "\n",
    "    for i in range(num_repetitions):\n",
    "        print(f\"\\n--- Repetition {i+1}/{num_repetitions} for {subset_name} ---\")\n",
    "        # Generate new USSP indices for each repetition\n",
    "        _, NICO_autumn_subsample_USSP_index = USSP.USSP(NICO_autumn_feature, UD)\n",
    "        indices = NICO_autumn_subsample_USSP_index\n",
    "\n",
    "        # train\n",
    "        model_path = f\"best_model_{subset_name}_rep{i+1}.pth\"\n",
    "        best_val_acc, log = NICO_ResNet50_TrainTest.train_model(full_train_set, indices, model_path, 16, 30)\n",
    "        all_val_accs.append(best_val_acc)\n",
    "        all_logs.append(log)\n",
    "\n",
    "        # test\n",
    "        test_accs = NICO_ResNet50_TrainTest.test_scenarios(model_path)\n",
    "        all_test_accs_list.append(test_accs)\n",
    "\n",
    "    # Calculate average validation accuracy\n",
    "    avg_val_acc = np.mean(all_val_accs)\n",
    "\n",
    "    # Calculate average test accuracy across all scenarios\n",
    "    all_scenario_names = set()\n",
    "    for test_accs in all_test_accs_list:\n",
    "        all_scenario_names.update(test_accs.keys())\n",
    "\n",
    "    avg_test_accs = {}\n",
    "    for scenario in all_scenario_names:\n",
    "        scenario_accuracies = [accs.get(scenario, 0) for accs in all_test_accs_list]\n",
    "        avg_test_accs[scenario] = np.mean(scenario_accuracies)\n",
    "\n",
    "    # Store the average results\n",
    "    all_results[subset_name] = {\n",
    "        'avg_val_acc': avg_val_acc,\n",
    "        'avg_test_accs': avg_test_accs,\n",
    "        'all_logs': all_logs # Optionally store all logs\n",
    "    }\n",
    "\n",
    "# Result print\n",
    "print(\"\\nAverage accuracy results across 20 repetitions:\")\n",
    "for subset_name, metrics in all_results.items():\n",
    "    avg_test_overall = np.mean(list(metrics['avg_test_accs'].values()))\n",
    "    print(f\"{subset_name}: AvgValAcc={metrics['avg_val_acc']:.1f}% | AvgTestAcc={avg_test_overall:.1f}%\")\n",
    "\n",
    "    print(f\"\\nDetailed average test accuracy per scenario for {subset_name}:\")\n",
    "    for scenario, avg_acc in metrics['avg_test_accs'].items():\n",
    "        print(f\"  {scenario}: {avg_acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the results to matlab to plot\n",
    "# subset_names = list(all_results.keys())\n",
    "subset_names=['all','Lowcon','IBOSS','srs','USSP']\n",
    "# scenario_names =['dim','dim_noisy','grass','grass_noisy','outdoor','outdoor_noisy','rock','rock_noisy','water','water_noisy']   \n",
    "scenario_names = list(list(all_results.values())[0]['test_accs'].keys())    \n",
    "acc_matrix = np.zeros((len(all_results), len(scenario_names)))\n",
    "\n",
    "# fix the matrix\n",
    "for row_idx, subset_name in enumerate(subset_names):\n",
    "    test_accs = all_results[subset_name]['test_accs']\n",
    "    row_data = [test_accs[scenario] for scenario in scenario_names]\n",
    "    acc_matrix[row_idx, :] = row_data\n",
    "\n",
    "# Construct a dictionary containing the matrix and labels\n",
    "save_dict = {\n",
    "    'acc_matrix': acc_matrix,            # accuracy matrix \n",
    "    'scenario_names': scenario_names,    # col labels\n",
    "    'subset_names': subset_names         # row labels\n",
    "}\n",
    "\n",
    "# save to .mat file\n",
    "savemat('cross_subset_accuracy.mat', save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USSP with different subsample numbers\n",
    "import numpy as np\n",
    "import USSP\n",
    "reload(USSP)\n",
    "\n",
    "NICO_autumn_feature=np.load('supervised_features.npy')\n",
    "n_values = [200, 500, 800, 1000, 1500, 2000, 2500, 3000, 4000]\n",
    "results = []\n",
    "\n",
    "for n in n_values:\n",
    "    filename_ud = f'UD_{n}_10.npy'\n",
    "    try:\n",
    "        UD = np.load(filename_ud)\n",
    "        _, NICO_autumn_subsample_USSP_index = USSP.USSP(NICO_autumn_feature, UD)\n",
    "        results.append(NICO_autumn_subsample_USSP_index)\n",
    "        print(f\"Processed n = {n}, loaded {filename_ud}, and stored the index.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {filename_ud} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing n = {n}: {e}\")\n",
    "\n",
    "# The results list contains the NICO_autumn_subsample_USSP_index obtained after running USSP.USSP for each n value\n",
    "print(\"\\nResults (list of NICO_autumn_subsample_USSP_index for each n):\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"n = {n_values[i]}: {result.shape if isinstance(result, np.ndarray) else result}\")\n",
    "\n",
    "import NICO_ResNet50_TrainTest\n",
    "reload(NICO_ResNet50_TrainTest)\n",
    "all_results_2 = {}\n",
    "for i, indices in enumerate(results):\n",
    "    n_value = n_values[i]\n",
    "    subset_name = f\"USSP_n_{n_value}\"\n",
    "    print(f\"\\nTraining and testing model for {subset_name} with {len(indices)} indices.\")\n",
    "\n",
    "    # Training phase\n",
    "    model_path = f\"best_model_{subset_name}.pth\"  # Name the model according to the subset name\n",
    "    best_val_acc, log = NICO_ResNet50_TrainTest.train_model(full_train_set, indices, model_path, 64, 30,0.001) # Reduce epochs for demonstration\n",
    "\n",
    "    # Testing phase\n",
    "    test_accs = NICO_ResNet50_TrainTest.test_scenarios(model_path)\n",
    "\n",
    "    # Record the results (using readable names)\n",
    "    all_results_2[subset_name] = {\n",
    "        'val_acc': best_val_acc,\n",
    "        'test_accs': test_accs,\n",
    "        'log': log\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the esNet50\n",
    "import NICO_ResNet50_TrainTest\n",
    "reload(NICO_ResNet50_TrainTest)\n",
    "all_results_2 = {}\n",
    "for i, indices in enumerate(results):\n",
    "    n_value = n_values[i]\n",
    "    subset_name = f\"USSP_n_{n_value}\"\n",
    "    print(f\"\\nTraining and testing model for {subset_name} with {len(indices)} indices.\")\n",
    "\n",
    "    # Train\n",
    "    model_path = f\"best_model_{subset_name}.pth\"  \n",
    "    best_val_acc, log = NICO_ResNet50_TrainTest.train_model(full_train_set, indices, model_path,  32, 30,0.0005) \n",
    "\n",
    "    # Test\n",
    "    test_accs = NICO_ResNet50_TrainTest.test_scenarios(model_path)\n",
    "\n",
    "    # Records\n",
    "    all_results_2[subset_name] = {\n",
    "        'val_acc': best_val_acc,\n",
    "        'test_accs': test_accs,\n",
    "        'log': log\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result analysis (comparison with readable names)\n",
    "print(\"\\nPerformance comparison across subsets:\")\n",
    "for subset_name, metrics in all_results_2.items():\n",
    "    avg_test = np.mean(list(metrics['test_accs'].values()))\n",
    "    print(f\"{subset_name}: ValAcc={metrics['val_acc']:.1f}% | AvgTestAcc={avg_test:.1f}%\")\n",
    "\n",
    "# Output as a table\n",
    "print(\"\\nTest Accuracy per Scenario:\")\n",
    "\n",
    "# Get the names of all test scenarios as column names\n",
    "all_scenario_names = set()\n",
    "for metrics in all_results_2.values():\n",
    "    all_scenario_names.update(metrics['test_accs'].keys())\n",
    "\n",
    "def custom_sort_key(scenario_name):\n",
    "    if scenario_name.endswith(\"_original\"):\n",
    "        return (scenario_name[:-9], 0)  # Original ones come first (0)\n",
    "    elif scenario_name.endswith(\"_noisy\"):\n",
    "        return (scenario_name[:-6], 1)  # Noisy ones come last (1)\n",
    "    else:\n",
    "        return (scenario_name, 2)  # Other cases in the middle (2)\n",
    "\n",
    "scenario_names = sorted(list(all_scenario_names), key=custom_sort_key)\n",
    "\n",
    "# Print the table header\n",
    "header = [\"Index\"] + [name for name in scenario_names]\n",
    "print(\"| \" + \" | \".join(header) + \" |\")\n",
    "print(\"|\" + \"---|\" * (len(header)))\n",
    "\n",
    "# Print the results for each row\n",
    "for subset_name, metrics in all_results_2.items():\n",
    "    row = [subset_name.split('_')[-1]]  # Use the n value as the Index\n",
    "    for scenario in scenario_names:\n",
    "        accuracy = metrics['test_accs'].get(scenario, \"N/A\")\n",
    "        row.append(f\"{accuracy:.1f}%\" if isinstance(accuracy, (int, float)) else accuracy)\n",
    "    print(\"| \" + \" | \".join(row) + \" |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running time compare\n",
    "import numpy as np\n",
    "import USSP\n",
    "import IBOSS\n",
    "import LowCon\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Define the value list for d and n\n",
    "d_values = 10\n",
    "n_values = [200, 500, 800, 1000, 1500, 2000, 2500, 3000, 4000]\n",
    "totalnumber = 27282\n",
    "\n",
    "# Ensure the directory for saving npy files is the same as the current script, or provide the correct path\n",
    "output_dir = \".\"  # Assuming npy files are saved in the current directory\n",
    "\n",
    "# Dictionary to store all test results (modified to have method as the outer key)\n",
    "all_results = {\n",
    "    'USSP': {},\n",
    "    'IBOSS': {},\n",
    "    'Lowcon': {},\n",
    "    'SRS': {}\n",
    "}\n",
    "\n",
    "# Generate normally distributed points K\n",
    "K = np.random.randn(totalnumber, d_values)\n",
    "\n",
    "for N in n_values:\n",
    "    filename = f\"lhd_design_d{d_values}_n{N}.npy\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    try:\n",
    "        LHD = np.load(filepath)\n",
    "        UD = LHD.copy()  # Assign the same data to LHD and UD\n",
    "        print(f\"\\n--- d={d_values}, N={N}, totalnumber={totalnumber} ---\")\n",
    "\n",
    "        # Time USSP\n",
    "        start_time = time.time()\n",
    "        _, _ = USSP.USSP(K, UD)\n",
    "        end_time = time.time()\n",
    "        all_results['USSP'][N] = f\"{end_time - start_time:.6f}\"\n",
    "\n",
    "        # Time IBOSS\n",
    "        start_time = time.time()\n",
    "        _, _ = IBOSS.IBOSS(K, N)\n",
    "        end_time = time.time()\n",
    "        all_results['IBOSS'][N] = f\"{end_time - start_time:.6f}\"\n",
    "\n",
    "        # Time Lowcon\n",
    "        start_time = time.time()\n",
    "        _ = LowCon.LowCon(K, LHD)\n",
    "        end_time = time.time()\n",
    "        all_results['Lowcon'][N] = f\"{end_time - start_time:.6f}\"\n",
    "\n",
    "        # Time srs\n",
    "        start_time = time.time()\n",
    "        _ = np.random.choice(totalnumber, size=N, replace=False)\n",
    "        end_time = time.time()\n",
    "        all_results['SRS'][N] = f\"{end_time - start_time:.6f}\"\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File {filepath} not found, skipping the combination of d={d_values}, N={N}.\")\n",
    "\n",
    "# Output results table\n",
    "print(\"\\n--- Execution Time of Sampling Methods (Unit: Seconds) ---\")\n",
    "header = [\"n_values\"] + list(all_results.keys())\n",
    "print(\"| \" + \" | \".join(header) + \" |\")\n",
    "print(\"|\" + \"---|\" * (len(header)))\n",
    "\n",
    "for n_val in n_values:\n",
    "    row = [str(n_val)]\n",
    "    for method in all_results.keys():\n",
    "        row.append(all_results[method].get(n_val, \"N/A\"))\n",
    "    print(\"| \" + \" | \".join(row) + \" |\")\n",
    "\n",
    "print(\"\\nTiming of all functions completed and output as a table.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
